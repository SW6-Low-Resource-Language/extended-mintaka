{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we used different resources:\n",
    "https://huggingface.co/docs/transformers/index\n",
    "https://huggingface.co/docs/transformers/tasks/question_answering\n",
    "https://huggingface.co/docs/transformers/model_doc/llama3 - https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct\n",
    "\n",
    "We want to fine-tune Llama3-70B with our data.\n",
    "As we understand right now, the traditional question-answer transformer needs:\n",
    "\t- context\n",
    "\t- question\n",
    "\t- answer found in context\n",
    "\n",
    "With mintaka we have no context, but instead wikidata entities. \n",
    "Do we find some transformer that takes question entities and answer entities separately?\n",
    "What kind of transformer do we need to do this?\n",
    "\n",
    "We need to convert all inputs to type string(at least the numerical answers, maybe more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "# import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the dataset from the mintaka data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"../dataset-generation/data/\"\n",
    "train_file = path_to_data+\"mintaka_train.json\"\n",
    "test_file = path_to_data+\"mintaka_test.json\"\n",
    "dev_file = path_to_data+\"mintaka_dev.json\"\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": dev_file, \"validation\": dev_file})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we preprocess the data to prepare it for the Llama model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_trained_model = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trained_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "\t# https://huggingface.co/transformers/v3.0.2/preprocessing.html\n",
    "\t# Look at 'Preprocessing pars of sentences'\n",
    "\t# encoded_input = tokenizer(\"How old are you?\", \"I'm 6 years old\")\n",
    "\t# print(encoded_input)\n",
    "\n",
    "\treturn {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map and test our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = dataset.map(preprocess_data, bached=True)\n",
    "\n",
    "print(processed_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh -J mlundg22@student.aau.dk@sshgw.aau.dk -l mlundg22@student.aau.dk ailab-fe01.srv.aau.dk\n",
    "ssh -J sd48tq@student.aau.dk@sshgw.aau.dk -l sd48tq@student.aau.dk ailab-fe01.srv.aau.dk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
